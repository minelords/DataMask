import gradio as gr
import requests
import cv2
import numpy as np
import os
from tempfile import NamedTemporaryFile

# ======================= é…ç½®éƒ¨åˆ† =======================
# ----------------- æ–‡æœ¬è„±æ•é…ç½® -----------------
TEXT_API_URL = "http://localhost:8081/api/text"

# ----------------- å›¾åƒè„±æ•é…ç½® -----------------
FACE_API_URL = "http://localhost:8000/api/v1/recognition/recognize"
FACE_API_KEY = "96f83d97-025f-4df4-bc5b-3881411f36ad"
TEMP_DIR = os.path.join(os.getcwd(), "temp_files")       # ä¸´æ—¶æ–‡ä»¶ç›®å½•
os.makedirs(TEMP_DIR, exist_ok=True)                     # ç¡®ä¿ç›®å½•å­˜åœ¨

# ====================== æ–‡æœ¬å¤„ç†æ¨¡å— ======================
def text_deidentify(text):
    """è°ƒç”¨æ–‡æœ¬è„±æ•æœåŠ¡"""
    try:
        response = requests.post(
            TEXT_API_URL,
            json={"text": text},
            timeout=10
        )
        return response.json().get("result", "å¤„ç†å¤±è´¥") if response.ok else "æœåŠ¡å“åº”å¼‚å¸¸"
    except Exception as e:
        return f"æœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}"

# ====================== å›¾åƒå¤„ç†æ¨¡å— ======================
def safe_image_write(image, path):
    """å®‰å…¨å†™å…¥å›¾åƒæ–‡ä»¶"""
    try:
        ret, buf = cv2.imencode('.jpg', image)
        if ret:
            with open(path, 'wb') as f:
                f.write(buf.tobytes())
            return True
        return False
    except Exception as e:
        print(f"å›¾åƒå†™å…¥å¤±è´¥: {str(e)}")
        return False

def get_face_landmarks(image):
    """è·å–äººè„¸å…³é”®ç‚¹ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰"""
    temp_path = os.path.join(TEMP_DIR, f"temp_{os.getpid()}.jpg")
    if not safe_image_write(image, temp_path):
        return []
    
    try:
        with open(temp_path, 'rb') as f:
            response = requests.post(
                FACE_API_URL,
                headers={"x-api-key": FACE_API_KEY},
                params={"face_plugins": "landmarks"},
                files={"file": f},
                timeout=15
            )
        return response.json().get('result', []) if response.ok else []
    except Exception as e:
        print(f"äººè„¸æ£€æµ‹APIé”™è¯¯: {str(e)}")
        return []
    finally:
        try:
            os.remove(temp_path)
        except PermissionError:
            print(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {temp_path}")

def anonymize_image(image, blur_type, width_ratio, height_ratio, kernel_size, sigma):
    """å›¾åƒè„±æ•æ ¸å¿ƒé€»è¾‘"""
    # å‚æ•°éªŒè¯
    kernel_size = max(3, int(kernel_size // 2 * 2 + 1))  # ç¡®ä¿å¥‡æ•°
    sigma = max(1, min(sigma, 100))
    
    detection_results = get_face_landmarks(image)
    if not detection_results:
        return image, "æœªæ£€æµ‹åˆ°äººè„¸"
    
    processed = image.copy()
    face_count = 0
    
    for face in detection_results:
        face_count += 1
        box = face.get("box", {})
        if not box:
            continue
        
        x_min = max(0, box.get("x_min", 0))
        y_min = max(0, box.get("y_min", 0))
        x_max = min(processed.shape[1], box.get("x_max", 0))
        y_max = min(processed.shape[0], box.get("y_max", 0))
        
        if blur_type == "face":
            # å…¨è„¸æ¨¡ç³Š
            face_roi = processed[y_min:y_max, x_min:x_max]
            h, w = face_roi.shape[:2]
            ksize = (min(w//2 * 2+1, 99), min(h//2 * 2+1, 99))
            processed[y_min:y_max, x_min:x_max] = cv2.GaussianBlur(face_roi, ksize, sigma)
        elif blur_type == "eyes":
            # çœ¼éƒ¨æ¨¡ç³Š
            landmarks = face.get("landmarks", [])
            if len(landmarks) >= 2:
                left_eye = np.array(landmarks[0])
                right_eye = np.array(landmarks[1])
                eye_distance = np.linalg.norm(right_eye - left_eye)
                
                for eye in [left_eye, right_eye]:
                    x1 = int(eye[0] - eye_distance * width_ratio / 2)
                    y1 = int(eye[1] - eye_distance * height_ratio / 2)
                    x2 = int(eye[0] + eye_distance * width_ratio / 2)
                    y2 = int(eye[1] + eye_distance * height_ratio / 2)
                    
                    # è¾¹ç•Œæ£€æŸ¥
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(processed.shape[1], x2), min(processed.shape[0], y2)
                    
                    if x2 > x1 and y2 > y1:
                        eye_roi = processed[y1:y2, x1:x2]
                        ksize = (min((x2-x1)//2 * 2+1,99), min((y2-y1)//2 * 2+1,99))
                        processed[y1:y2, x1:x2] = cv2.GaussianBlur(eye_roi, ksize, sigma)
    
    return processed, f"å¤„ç†å®Œæˆï¼šæ£€æµ‹åˆ° {face_count} å¼ äººè„¸"

# ====================== Gradioç•Œé¢ ======================
with gr.Blocks(title="æ•°æ®è„±æ•ç³»ç»Ÿ", css=".gradio-container {max-width: 1200px}") as app:
    gr.Markdown("# ğŸ” éšç§æ•°æ®è„±æ•å¹³å°")
    
    with gr.Tabs():
        # ----------------- æ–‡æœ¬è„±æ•æ ‡ç­¾é¡µ -----------------
        with gr.TabItem("æ–‡æœ¬è„±æ•"):
            with gr.Row():
                text_input = gr.Textbox(
                    label="è¾“å…¥æ–‡æœ¬", 
                    lines=7, 
                    placeholder="è¯·è¾“å…¥éœ€è¦è„±æ•çš„æ–‡æœ¬..."
                )
                text_output = gr.Textbox(label="å¤„ç†ç»“æœ", lines=7, interactive=False)
            
            # æ·»åŠ ç‹¬ç«‹ç¤ºä¾‹ç»„ä»¶
            gr.Examples(
                examples=[
                    ["ç”¨æˆ·é‚®ç®±ï¼štest@example.comï¼Œç”µè¯ï¼š13800138000"],
                    ["åœ°å€ï¼šåŒ—äº¬å¸‚æœé˜³åŒºå»ºå›½é—¨å¤–å¤§è¡—1å·"],
                    ["èº«ä»½è¯å·ç :330281201401239319,å‡ºç”Ÿæ—¥æœŸ:2014-01-23,æ€§åˆ«:ç”·,å¹´é¾„:11,å‡ºç”Ÿåœ°:æµ™æ±Ÿçœ å®æ³¢å¸‚ ä½™å§šå¸‚"]
                ],
                inputs=text_input,
                label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿè¾“å…¥",
                examples_per_page=3
            )
            
            text_btn = gr.Button("æ‰§è¡Œè„±æ•", variant="primary")

        # ----------------- å›¾åƒè„±æ•æ ‡ç­¾é¡µ -----------------
        with gr.TabItem("å›¾åƒè„±æ•"):
            gr.Markdown("### äººè„¸éšç§ä¿æŠ¤")
            with gr.Row():
                with gr.Column():
                    img_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡", type="numpy")
                    with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                        with gr.Group():
                            blur_type = gr.Dropdown(
                                ["face", "eyes"],
                                value="eyes",
                                label="è„±æ•æ–¹å¼"
                            )
                            width_ratio = gr.Slider(
                                0.1, 2.0, 1.5,
                                step=0.1,
                                label="çœ¼éƒ¨åŒºåŸŸå®½åº¦æ¯”ä¾‹"
                            )
                            height_ratio = gr.Slider(
                                0.1, 2.0, 0.6,
                                step=0.1,
                                label="çœ¼éƒ¨åŒºåŸŸé«˜åº¦æ¯”ä¾‹"
                            )
                            kernel_size = gr.Slider(
                                3, 99, 35,
                                step=2,
                                label="æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰"
                            )
                            sigma = gr.Slider(
                                1, 100, 20,
                                label="æ¨¡ç³Šå¼ºåº¦"
                            )
                    img_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")
                
                with gr.Column():
                    img_output = gr.Image(label="å¤„ç†ç»“æœ", interactive=False)
                    info_output = gr.Textbox(label="å¤„ç†ä¿¡æ¯", interactive=False)
            
            gr.Examples(
                examples=[os.path.join("examples", f) for f in ["1.jpg", "2.jpg","3.jpg"]],
                inputs=img_input,
                label="ğŸ–¼ï¸ ç¤ºä¾‹å›¾ç‰‡"
            )

    # ==================== äº‹ä»¶ç»‘å®š ====================
    text_btn.click(
        fn=text_deidentify,
        inputs=text_input,
        outputs=text_output
    )
    
    img_btn.click(
        fn=anonymize_image,
        inputs=[img_input, blur_type, width_ratio, height_ratio, kernel_size, sigma],
        outputs=[img_output, info_output]
    )

# ==================== å¯åŠ¨åº”ç”¨ ====================
if __name__ == "__main__":
    # æƒé™æ£€æŸ¥
    if not os.access(TEMP_DIR, os.W_OK):
        raise PermissionError(f"ä¸´æ—¶ç›®å½•ä¸å¯å†™: {TEMP_DIR}")
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True
    )

def text_deidentify(text):
    """è°ƒç”¨Goæ–‡æœ¬è„±æ•æœåŠ¡"""
    try:
        response = requests.post(
            TEXT_API_URL,
            json={"text": text},
            timeout=10
        )
        if response.status_code == 200:
            return response.json()["result"]
        return f"é”™è¯¯ï¼šæœåŠ¡è¿”å›çŠ¶æ€ç  {response.status_code}"
    except Exception as e:
        return f"APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"

def validate_kernel_size(ks):
    """ç¡®ä¿æ ¸å¤§å°ä¸ºæ­£å¥‡æ•°"""
    return (max(1, ks[0] // 2 * 2 + 1), max(1, ks[1] // 2 * 2 + 1))

def get_face_landmarks(image):
    """è·å–äººè„¸å…³é”®ç‚¹"""
    with NamedTemporaryFile(suffix=".jpg") as temp:
        cv2.imwrite(temp.name, image)
        try:
            response = requests.post(
                FACE_API_URL,
                headers={"x-api-key": FACE_API_KEY},
                params={"face_plugins": "landmarks"},
                files={"file": open(temp.name, "rb")},
                timeout=15
            )
            return response.json().get('result', []) if response.ok else []
        except Exception as e:
            print(f"äººè„¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return []

def image_anonymize(image, blur_type, width_ratio, height_ratio, kernel_size, sigma):
    """å›¾åƒè„±æ•å¤„ç†"""
    # å‚æ•°æ ¡éªŒ
    kernel_size = validate_kernel_size((kernel_size, kernel_size))
    sigma = max(1, min(sigma, 100))
    
    # è·å–æ£€æµ‹ç»“æœ
    detection_results = get_face_landmarks(image)
    if not detection_results:
        return image, "æœªæ£€æµ‹åˆ°äººè„¸"
    
    processed = image.copy()
    faces_count = 0
    
    for face in detection_results:
        faces_count += 1
        box = face["box"]
        x_min, y_min = max(0, box["x_min"]), max(0, box["y_min"])
        x_max, y_max = min(image.shape[1], box["x_max"]), min(image.shape[0], box["y_max"])

        if blur_type == "face":
            # å…¨è„¸æ¨¡ç³Š
            face_roi = processed[y_min:y_max, x_min:x_max]
            h, w = face_roi.shape[:2]
            ksize = (min(w//2 * 2+1, 99), min(h//2 * 2+1, 99))
            processed[y_min:y_max, x_min:x_max] = cv2.GaussianBlur(face_roi, ksize, sigma)
        elif blur_type == "eyes" and "landmarks" in face:
            # çœ¼éƒ¨æ¨¡ç³Š
            landmarks = face["landmarks"]
            if len(landmarks) >= 2:
                left_eye = np.array(landmarks[0])
                right_eye = np.array(landmarks[1])
                eye_distance = np.linalg.norm(right_eye - left_eye)
                
                for eye in [left_eye, right_eye]:
                    x1 = int(eye[0] - eye_distance * width_ratio / 2)
                    y1 = int(eye[1] - eye_distance * height_ratio / 2)
                    x2 = int(eye[0] + eye_distance * width_ratio / 2)
                    y1, y2 = max(0,y1), min(processed.shape[0],y2)
                    x1, x2 = max(0,x1), min(processed.shape[1],x2)
                    
                    if x2 > x1 and y2 > y1:
                        eye_roi = processed[y1:y2, x1:x2]
                        ksize = (min((x2-x1)//2 * 2+1,99), min((y2-y1)//2 * 2+1,99))
                        processed[y1:y2, x1:x2] = cv2.GaussianBlur(eye_roi, ksize, sigma)
    
    return processed, f"å¤„ç†å®Œæˆï¼šæ£€æµ‹åˆ° {faces_count} å¼ äººè„¸"

# ----------------- Gradioç•Œé¢ -----------------
with gr.Blocks(title="ç»¼åˆè„±æ•ç³»ç»Ÿ", css=".gradio-container {max-width: 1200px !important}") as app:
    gr.Markdown("# ğŸ”’ æ•æ„Ÿæ•°æ®è„±æ•å·¥ä½œå°")
    
    with gr.Tabs():
        with gr.TabItem("æ–‡æœ¬è„±æ•"):
            with gr.Row():
                text_input = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=7, placeholder="è¯·è¾“å…¥éœ€è¦è„±æ•çš„æ–‡æœ¬...")
                text_output = gr.Textbox(label="å¤„ç†ç»“æœ", lines=7, interactive=False)
            text_btn = gr.Button("æ‰§è¡Œè„±æ•", variant="primary")
            examples=[
                ["ç”¨æˆ·é‚®ç®±ï¼štest@example.comï¼Œç”µè¯ï¼š13800138000"],
                ["åœ°å€ï¼šåŒ—äº¬å¸‚æœé˜³åŒºå»ºå›½é—¨å¤–å¤§è¡—1å·"]
            ]
        
        with gr.TabItem("å›¾åƒè„±æ•"):
            with gr.Row():
                with gr.Column():
                    img_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡", type="numpy")
                    with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                        blur_type = gr.Dropdown(
                            ["face", "eyes"], value="eyes", label="è„±æ•æ–¹å¼",
                            info="é€‰æ‹©å…¨è„¸æ¨¡ç³Šæˆ–çœ¼éƒ¨æ¨¡ç³Š"
                        )
                        width_ratio = gr.Slider(0.1, 2.0, 0.6, step=0.1, label="çœ¼éƒ¨åŒºåŸŸå®½åº¦æ¯”ä¾‹")
                        height_ratio = gr.Slider(0.1, 2.0, 0.4, step=0.1, label="çœ¼éƒ¨åŒºåŸŸé«˜åº¦æ¯”ä¾‹")
                        kernel_size = gr.Slider(3, 99, 35, step=2, label="æ¨¡ç³Šæ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼‰")
                        sigma = gr.Slider(1, 100, 30, label="æ¨¡ç³Šå¼ºåº¦")
                with gr.Column():
                    img_output = gr.Image(label="å¤„ç†ç»“æœ", interactive=False)
                    info_output = gr.Textbox(label="å¤„ç†ä¿¡æ¯", interactive=False)
            img_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")

    # äº‹ä»¶å¤„ç†
    text_btn.click(
        fn=text_deidentify,
        inputs=text_input,
        outputs=text_output
    )
    
    img_btn.click(
        fn=image_anonymize,
        inputs=[img_input, blur_type, width_ratio, height_ratio, kernel_size, sigma],
        outputs=[img_output, info_output]
    )

# ----------------- å¯åŠ¨åº”ç”¨ -----------------
if __name__ == "__main__":
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        share=True
    )
